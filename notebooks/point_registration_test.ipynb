{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test point-based registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "import planeslam.geometry as geometry\n",
    "import planeslam.io as io\n",
    "from planeslam.scanrep import ScanRep, pc_to_scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in airsim LiDAR and pose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in point cloud data\n",
    "binpath = os.path.join(os.getcwd(),'..', 'data', 'airsim', 'blocks_20_samples_1', 'lidar', 'Drone0')\n",
    "PC_data = io.read_lidar_bin(binpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ground-truth poses (in drone local frame)\n",
    "posepath = os.path.join(os.getcwd(),'..', 'data', 'airsim', 'blocks_20_samples_1', 'poses', 'Drone0')\n",
    "drone_positions, drone_orientations = io.read_poses(posepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open3D ICP registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helper\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4459,\n",
    "                                      front=[0.9288, -0.2951, -0.2242],\n",
    "                                      lookat=[1.6784, 2.0612, 1.4451],\n",
    "                                      up=[-0.3402, -0.9189, -0.1996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize source and target\n",
    "source = o3d.geometry.PointCloud()\n",
    "source.points = o3d.utility.Vector3dVector(PC_data[0])\n",
    "\n",
    "target = o3d.geometry.PointCloud()\n",
    "target.points = o3d.utility.Vector3dVector(PC_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "o3d.visualization.draw_geometries([source, target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=4.595588e-04, inlier_rmse=1.658737e-02, and correspondence_set size of 3\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "# Initial guess transform \n",
    "trans_init = np.eye(4)\n",
    "threshold = 0.02\n",
    "\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=6.280637e-03, inlier_rmse=1.329315e-02, and correspondence_set size of 41\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 9.62607006e-01  7.05381633e-05  2.70901728e-01 -9.08054546e-01]\n",
      " [-1.56330597e-04  9.99999944e-01  2.95113544e-04 -6.75400308e-03]\n",
      " [-2.70901692e-01 -3.26428594e-04  9.62606964e-01 -4.43856240e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6544a4f6c4c81bb627ffe33e2e2069de7ceab5a334b7c2380b1b0001fbb739c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
