{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test point-based registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import planeslam.io as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in airsim LiDAR and pose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in point cloud data\n",
    "binpath = os.path.join(os.getcwd(),'..', 'data', 'airsim', 'blocks_20_samples_1', 'lidar', 'Drone0')\n",
    "PC_data = io.read_lidar_bin(binpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in ground-truth poses (in drone local frame)\n",
    "posepath = os.path.join(os.getcwd(),'..', 'data', 'airsim', 'blocks_20_samples_1', 'poses', 'Drone0')\n",
    "drone_positions, drone_orientations = io.read_poses(posepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open3D ICP registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization helper\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4459,\n",
    "                                      front=[0.9288, -0.2951, -0.2242],\n",
    "                                      lookat=[1.6784, 2.0612, 1.4451],\n",
    "                                      up=[-0.3402, -0.9189, -0.1996])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize source and target\n",
    "source = o3d.geometry.PointCloud()\n",
    "source.points = o3d.utility.Vector3dVector(PC_data[0])\n",
    "source.estimate_normals()\n",
    "source.orient_normals_towards_camera_location()\n",
    "\n",
    "target = o3d.geometry.PointCloud()\n",
    "target.points = o3d.utility.Vector3dVector(PC_data[1])\n",
    "target.estimate_normals()\n",
    "target.orient_normals_towards_camera_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The handle is invalid. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: The requested transformation operation is not supported. \n"
     ]
    }
   ],
   "source": [
    "# Visualize\n",
    "o3d.visualization.draw_geometries([target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegistrationResult with fitness=4.595588e-04, inlier_rmse=1.658737e-02, and correspondence_set size of 3\n",
      "Access transformation to get result.\n"
     ]
    }
   ],
   "source": [
    "# Initial guess transform \n",
    "trans_init = np.eye(4)\n",
    "threshold = 0.02\n",
    "\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-point ICP\n",
      "Elapased time:  0.12083935737609863\n",
      "RegistrationResult with fitness=6.280637e-03, inlier_rmse=1.329315e-02, and correspondence_set size of 41\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 9.62607006e-01  7.05381633e-05  2.70901728e-01 -9.08054546e-01]\n",
      " [-1.56330597e-04  9.99999944e-01  2.95113544e-04 -6.75400308e-03]\n",
      " [-2.70901692e-01 -3.26428594e-04  9.62606964e-01 -4.43856240e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Point-to-point ICP\n",
    "print(\"Apply point-to-point ICP\")\n",
    "start_time = time.time()\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "print(\"Elapased time: \", time.time() - start_time)\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(source, target, reg_p2p.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Downloading https://github.com/isl-org/open3d_downloads/releases/download/20220201-data/DemoICPPointClouds.zip\n",
      "[Open3D INFO] Downloaded to C:\\Users\\adamd/open3d_data/download/DemoICPPointClouds/DemoICPPointClouds.zip\n",
      "[Open3D INFO] Extracting C:\\Users\\adamd/open3d_data/download/DemoICPPointClouds/DemoICPPointClouds.zip.\n",
      "[Open3D INFO] Extracted to C:\\Users\\adamd/open3d_data/extract/DemoICPPointClouds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.62956297,  0.66870427, -0.39558202],\n",
       "       [ 0.01322357,  0.06152465, -0.99801797],\n",
       "       [ 0.01659746,  0.06297147, -0.99787724],\n",
       "       ...,\n",
       "       [-0.24384584, -0.52947396, -0.81252468],\n",
       "       [-0.05902789, -0.70068824, -0.71102154],\n",
       "       [-0.15078427, -0.55733532, -0.81648111]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "\n",
    "np.asarray(source.normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply point-to-plane ICP\n",
      "Elapased time:  0.05086207389831543\n",
      "RegistrationResult with fitness=0.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 0\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[ 9.99986532e-01  3.46789296e-03 -3.86133754e-03 -2.71526439e-02]\n",
      " [-3.44794998e-03  9.99980745e-01  5.15951917e-03 -8.04419914e+05]\n",
      " [ 3.87915585e-03 -5.14613598e-03  9.99979235e-01  2.26548884e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Apply point-to-plane ICP\")\n",
    "start_time = time.time()\n",
    "reg_p2l = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "print(\"Elapased time: \", time.time() - start_time)\n",
    "print(reg_p2l)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2l.transformation)\n",
    "draw_registration_result(source, target, reg_p2l.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6544a4f6c4c81bb627ffe33e2e2069de7ceab5a334b7c2380b1b0001fbb739c2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
